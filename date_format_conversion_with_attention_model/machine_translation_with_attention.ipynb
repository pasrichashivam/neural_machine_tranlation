{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Bidirectional, Concatenate, Dot, Input, LSTM\n",
    "from keras.layers import RepeatVector, Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load_data: Loads data from file\n",
    "2. create_index_mapping: Creates the index - character mapping for human, machine readable dates vocabulary.\n",
    "3. string_to_int: Creates integer vectors from the character array (string).\n",
    "4. preprocess_data: Converts the integer vectors to the one-hot encoded vectors and returns these vectors along with vocabularies. (human_vocab, machine_vocab, inv_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    \n",
    "    def __init__(self, max_input_length, output_length):\n",
    "        self.max_input_length = max_input_length\n",
    "        self.output_length = output_length\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        self.data = pd.read_csv(path)\n",
    "    \n",
    "    def create_index_mapping(self):\n",
    "        human = set()\n",
    "        machine = set()\n",
    "        self.dataset = []\n",
    "        for t in self.data.itertuples():\n",
    "            h, m = t.human, t.machine\n",
    "            self.dataset.append((h, m))\n",
    "            human.update(h)\n",
    "            machine.update(m)\n",
    "        self.human_vocab = dict(zip(sorted(human) + ['<unk>', '<pad>'], list(range(len(human) + 2))))\n",
    "        self.inv_machine = dict(enumerate(sorted(machine)))\n",
    "        self.machine_vocab = {v:k for k,v in self.inv_machine.items()}\n",
    "        \n",
    "    def string_to_int(self, string, length, vocab):\n",
    "        string = string.lower()\n",
    "        string = string.replace(',','')\n",
    "        if len(string) > length:\n",
    "            string = string[:length]    \n",
    "        int_vector = list(map(lambda x: vocab[x], string))\n",
    "\n",
    "        if len(string) < length :\n",
    "            int_vector += [vocab['<pad>']] * (length - len(string))\n",
    "        return int_vector\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        X, Y = zip(*self.dataset)\n",
    "        X = np.array([self.string_to_int(i, self.max_input_length, self.human_vocab) for i in X])\n",
    "        Y = np.array([self.string_to_int(t, self.output_length, self.machine_vocab) for t in Y])\n",
    "        X_oh = to_categorical(X, num_classes=len(self.human_vocab))\n",
    "        Y_oh = to_categorical(Y, num_classes=len(self.machine_vocab))\n",
    "        return X_oh, Y_oh, self.human_vocab, self.machine_vocab,self.inv_machine   # (20000, 30, 37), (20000, 10, 11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. max_input_length: Define maximum length of the human readable date.\n",
    "2. output_length: YYYY-MM-DD is 10 characters long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length=30\n",
    "output_length = 10\n",
    "data_obj = DataPreprocess(max_input_length=max_input_length, output_length = output_length)\n",
    "data_obj.load_data('train_dates.csv')\n",
    "data_obj.create_index_mapping()\n",
    "X_train, Y_train, human_vocab, machine_vocab, inv_machine = data_obj.preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create encoder-decoder model with attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. init: Constructor used for initialization\n",
    "   * Variables: \n",
    "       * max_input_length: Maximum length of input\n",
    "       * output_length: Length of output.\n",
    "       * en_lstm_units: Number of Encoder Bidirectional LSTM units. \n",
    "       * de_lstm_units: Number of Decoder LSTM units.\n",
    "   * Layers to calculate context vector: We are initializing the layers and assigning it to variable because while iterating to generate output, it is important to have the same weights.(It should not re-initiaiize the weights every time after each output character).\n",
    "       * repeat_layer: It will replicate the decoder's previous state to the number of encoder's output.\n",
    "       * concat_layer: It will concatenate the encoder's output and decoder's preivous state.\n",
    "       * attention_dense, attention_weights: To calculate the attention weights passing the concatenated result through the small fully-connected network using softmax layer in output.\n",
    "       * context_vector: Contect vector which is the weighted sum (dot product) of encoder's output and the calculated attention weights.\n",
    "   * Decoder Layer's\n",
    "       * decoder_lstm_layer, output_layer: initialize Decoder's lstm and output layer.\n",
    "2. create_context_vector: This method will create the context vector for single output character.\n",
    "3. create_model: This method will create the whole network architecture.\n",
    "    * First Encoder activations are calculated using Bidirectional LSTM.\n",
    "    * Now for each character to predict:\n",
    "      * Create the context vectors.\n",
    "      * Input the context vector along with previous activation and cell_state to the Decoder LSTM layer.\n",
    "      * Output the character using dense layer and append it to the outputs list.\n",
    "      * So output will be the predicted list of characters for corresponding input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkArchitecture:\n",
    "    \n",
    "    def __init__(self, max_input_length, output_length, en_lstm_units, de_lstm_units):\n",
    "        # Initialze variables\n",
    "        self.max_input_length = max_input_length\n",
    "        self.output_length = output_length\n",
    "        self.en_lstm_units = en_lstm_units\n",
    "        self.de_lstm_units = de_lstm_units\n",
    "        # Initialize layers to calculate context vector\n",
    "        self.repeat_layer = RepeatVector(self.max_input_length, name = 'repeat_layer')\n",
    "        self.concat_layer = Concatenate(axis=-1, name = 'concatenate_layer')\n",
    "        self.attention_dense = Dense(1, activation = \"relu\", name = 'attention_dense')\n",
    "        self.attention_weights = Activation('softmax', name='attention_weights'\n",
    "        self.context_vector = Dot(axes = 1, name = 'context_vector')\n",
    "        # Initialize layers for decoder network\n",
    "        self.decoder_lstm_layer = LSTM(self.de_lstm_units, return_state = True, name = 'decoder_lstm')\n",
    "        self.output_layer = Dense(len(machine_vocab), activation='softmax', name = 'decoder_output')\n",
    "        \n",
    "    def create_context_vector(self, encoder_activation, decoder_prev_state):\n",
    "        decoder_prev_state = self.repeat_layer(decoder_prev_state)\n",
    "        concat = self.concat_layer([encoder_activation, decoder_prev_state])\n",
    "        att_dense = self.attention_dense(concat)\n",
    "        attention_weights = self.attention_weights(att_dense)\n",
    "        context = self.context_vector([attention_weights, encoder_activation])\n",
    "        return context\n",
    "    \n",
    "    def create_model(self):\n",
    "        encoder_input = Input(shape=(self.max_input_length, len(human_vocab)))\n",
    "        de_initial_hidden_state = Input(shape=(self.de_lstm_units,), name='initial_hidden_state')\n",
    "        de_initial_cell_state = Input(shape=(self.de_lstm_units,), name='initial_cell_state')\n",
    "        hidden_state = de_initial_hidden_state \n",
    "        cell_state = de_initial_cell_state\n",
    "        outputs = []\n",
    "\n",
    "        encoder_activations = Bidirectional(LSTM(self.en_lstm_units, return_sequences=True, name = 'encoder_bi-lstm'))(encoder_input)\n",
    "        for t in range(self.output_length):\n",
    "            context = self.create_context_vector(encoder_activations, cell_state)\n",
    "            hidden_state, _, cell_state = self.decoder_lstm_layer(context, initial_state = [hidden_state, cell_state])\n",
    "            out = self.output_layer(cell_state)\n",
    "            outputs.append(out)\n",
    "\n",
    "        model = Model(inputs = [encoder_input, de_initial_hidden_state, de_initial_cell_state], outputs = outputs)    \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialze variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lstm_units = 64\n",
    "de_lstm_units = 128\n",
    "decoder_state = np.zeros((X_train.shape[0], de_lstm_units))\n",
    "decoder_cell_state = np.zeros((X_train.shape[0], de_lstm_units))\n",
    "outputs = list(Y_train.swapaxes(0,1))  # (10, 20000, 11) output should be of shape (1, machine_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_obj = NetworkArchitecture(max_input_length = 30, output_length = 10, en_lstm_units = 64, de_lstm_units = 128)\n",
    "model = network_obj.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "initial_cell_state (InputLayer) (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 128)      52224       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_layer (RepeatVector)     (None, 30, 128)      0           initial_cell_state[0][0]         \n",
      "                                                                 decoder_lstm[0][2]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "                                                                 decoder_lstm[3][2]               \n",
      "                                                                 decoder_lstm[4][2]               \n",
      "                                                                 decoder_lstm[5][2]               \n",
      "                                                                 decoder_lstm[6][2]               \n",
      "                                                                 decoder_lstm[7][2]               \n",
      "                                                                 decoder_lstm[8][2]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_layer (Concatenate) (None, 30, 256)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[0][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[1][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[2][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[3][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[4][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[5][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[6][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[7][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[8][0]               \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_layer[9][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_dense (Dense)         (None, 30, 1)        257         concatenate_layer[0][0]          \n",
      "                                                                 concatenate_layer[1][0]          \n",
      "                                                                 concatenate_layer[2][0]          \n",
      "                                                                 concatenate_layer[3][0]          \n",
      "                                                                 concatenate_layer[4][0]          \n",
      "                                                                 concatenate_layer[5][0]          \n",
      "                                                                 concatenate_layer[6][0]          \n",
      "                                                                 concatenate_layer[7][0]          \n",
      "                                                                 concatenate_layer[8][0]          \n",
      "                                                                 concatenate_layer[9][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           attention_dense[0][0]            \n",
      "                                                                 attention_dense[1][0]            \n",
      "                                                                 attention_dense[2][0]            \n",
      "                                                                 attention_dense[3][0]            \n",
      "                                                                 attention_dense[4][0]            \n",
      "                                                                 attention_dense[5][0]            \n",
      "                                                                 attention_dense[6][0]            \n",
      "                                                                 attention_dense[7][0]            \n",
      "                                                                 attention_dense[8][0]            \n",
      "                                                                 attention_dense[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_vector (Dot)            (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "initial_hidden_state (InputLaye (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 128), (None, 131584      context_vector[0][0]             \n",
      "                                                                 initial_hidden_state[0][0]       \n",
      "                                                                 initial_cell_state[0][0]         \n",
      "                                                                 context_vector[1][0]             \n",
      "                                                                 decoder_lstm[0][0]               \n",
      "                                                                 decoder_lstm[0][2]               \n",
      "                                                                 context_vector[2][0]             \n",
      "                                                                 decoder_lstm[1][0]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 context_vector[3][0]             \n",
      "                                                                 decoder_lstm[2][0]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "                                                                 context_vector[4][0]             \n",
      "                                                                 decoder_lstm[3][0]               \n",
      "                                                                 decoder_lstm[3][2]               \n",
      "                                                                 context_vector[5][0]             \n",
      "                                                                 decoder_lstm[4][0]               \n",
      "                                                                 decoder_lstm[4][2]               \n",
      "                                                                 context_vector[6][0]             \n",
      "                                                                 decoder_lstm[5][0]               \n",
      "                                                                 decoder_lstm[5][2]               \n",
      "                                                                 context_vector[7][0]             \n",
      "                                                                 decoder_lstm[6][0]               \n",
      "                                                                 decoder_lstm[6][2]               \n",
      "                                                                 context_vector[8][0]             \n",
      "                                                                 decoder_lstm[7][0]               \n",
      "                                                                 decoder_lstm[7][2]               \n",
      "                                                                 context_vector[9][0]             \n",
      "                                                                 decoder_lstm[8][0]               \n",
      "                                                                 decoder_lstm[8][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 11)           1419        decoder_lstm[0][2]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "                                                                 decoder_lstm[3][2]               \n",
      "                                                                 decoder_lstm[4][2]               \n",
      "                                                                 decoder_lstm[5][2]               \n",
      "                                                                 decoder_lstm[6][2]               \n",
      "                                                                 decoder_lstm[7][2]               \n",
      "                                                                 decoder_lstm[8][2]               \n",
      "                                                                 decoder_lstm[9][2]               \n",
      "==================================================================================================\n",
      "Total params: 185,484\n",
      "Trainable params: 185,484\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph of Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 681.00 556.00\" width=\"681pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 677,-552 677,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140568402787408 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140568402787408</title>\n",
       "<polygon fill=\"none\" points=\"158.5,-511.5 158.5,-547.5 283.5,-547.5 283.5,-511.5 158.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-525.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140568400439000 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140568400439000</title>\n",
       "<polygon fill=\"none\" points=\"61,-438.5 61,-474.5 381,-474.5 381,-438.5 61,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-452.8\">bidirectional_1(encoder_bi-lstm): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140568402787408&#45;&gt;140568400439000 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140568402787408-&gt;140568400439000</title>\n",
       "<path d=\"M221,-511.313C221,-503.289 221,-493.547 221,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"224.5,-484.529 221,-474.529 217.5,-484.529 224.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568400438832 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140568400438832</title>\n",
       "<polygon fill=\"none\" points=\"28.5,-146.5 28.5,-182.5 201.5,-182.5 201.5,-146.5 28.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115\" y=\"-160.8\">initial_cell_state: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140569415242696 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140569415242696</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-0.5 29.5,-36.5 194.5,-36.5 194.5,-0.5 29.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112\" y=\"-14.8\">repeat_layer: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 140568400438832&#45;&gt;140569415242696 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140568400438832-&gt;140569415242696</title>\n",
       "<path d=\"M114.644,-146.416C114.132,-121.841 113.182,-76.2528 112.571,-46.9273\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"116.063,-46.4868 112.355,-36.5619 109.065,-46.6327 116.063,-46.4868\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140568403909768</title>\n",
       "<polygon fill=\"none\" points=\"215,-73.5 215,-109.5 349,-109.5 349,-73.5 215,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282\" y=\"-87.8\">decoder_lstm: LSTM</text>\n",
       "</g>\n",
       "<!-- 140568400438832&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge74\"><title>140568400438832-&gt;140568403909768</title>\n",
       "<path d=\"M155.001,-146.494C178.274,-136.599 207.803,-124.045 232.529,-113.533\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"233.914,-116.747 241.747,-109.614 231.175,-110.305 233.914,-116.747\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909656 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140568403909656</title>\n",
       "<polygon fill=\"none\" points=\"66,-365.5 66,-401.5 254,-401.5 254,-365.5 66,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-379.8\">concatenate_layer: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140568400439000&#45;&gt;140568403909656 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140568400439000-&gt;140568403909656</title>\n",
       "<path d=\"M206.234,-438.313C198.741,-429.592 189.504,-418.84 181.261,-409.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"183.802,-406.833 174.63,-401.529 178.492,-411.395 183.802,-406.833\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909824 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140568403909824</title>\n",
       "<polygon fill=\"none\" points=\"219.5,-146.5 219.5,-182.5 344.5,-182.5 344.5,-146.5 219.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"282\" y=\"-160.8\">context_vector: Dot</text>\n",
       "</g>\n",
       "<!-- 140568400439000&#45;&gt;140568403909824 -->\n",
       "<g class=\"edge\" id=\"edge53\"><title>140568400439000-&gt;140568403909824</title>\n",
       "<path d=\"M238.73,-438.373C247.645,-428.615 257.666,-415.636 263,-402 290.932,-330.59 288.289,-237.982 284.767,-192.763\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"288.236,-192.247 283.894,-182.582 281.261,-192.845 288.236,-192.247\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140569415242696&#45;&gt;140568403909656 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140569415242696-&gt;140568403909656</title>\n",
       "<path d=\"M86.0234,-36.5678C52.9375,-60.5988 0,-107.758 0,-163.5 0,-238.5 0,-238.5 0,-238.5 0,-297.36 60.5621,-338.3 107.167,-361.091\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"105.744,-364.29 116.279,-365.408 108.74,-357.964 105.744,-364.29\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909432 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140568403909432</title>\n",
       "<polygon fill=\"none\" points=\"90.5,-292.5 90.5,-328.5 233.5,-328.5 233.5,-292.5 90.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-306.8\">attention_dense: Dense</text>\n",
       "</g>\n",
       "<!-- 140568403909656&#45;&gt;140568403909432 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>140568403909656-&gt;140568403909432</title>\n",
       "<path d=\"M160.484,-365.313C160.71,-357.289 160.985,-347.547 161.237,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"164.737,-338.623 161.52,-328.529 157.74,-338.426 164.737,-338.623\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909376 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140568403909376</title>\n",
       "<polygon fill=\"none\" points=\"74.5,-219.5 74.5,-255.5 251.5,-255.5 251.5,-219.5 74.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-233.8\">attention_weights: Activation</text>\n",
       "</g>\n",
       "<!-- 140568403909432&#45;&gt;140568403909376 -->\n",
       "<g class=\"edge\" id=\"edge42\"><title>140568403909432-&gt;140568403909376</title>\n",
       "<path d=\"M162.242,-292.313C162.355,-284.289 162.492,-274.547 162.619,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.119,-265.577 162.76,-255.529 159.12,-265.479 166.119,-265.577\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909376&#45;&gt;140568403909824 -->\n",
       "<g class=\"edge\" id=\"edge52\"><title>140568403909376-&gt;140568403909824</title>\n",
       "<path d=\"M191.503,-219.494C207.43,-209.991 227.467,-198.036 244.637,-187.792\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246.522,-190.743 253.317,-182.614 242.936,-184.732 246.522,-190.743\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909824&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge72\"><title>140568403909824-&gt;140568403909768</title>\n",
       "<path d=\"M282,-146.313C282,-138.289 282,-128.547 282,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"285.5,-119.529 282,-109.529 278.5,-119.529 285.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568400438720 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140568400438720</title>\n",
       "<polygon fill=\"none\" points=\"362.5,-146.5 362.5,-182.5 553.5,-182.5 553.5,-146.5 362.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458\" y=\"-160.8\">initial_hidden_state: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140568400438720&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge73\"><title>140568400438720-&gt;140568403909768</title>\n",
       "<path d=\"M415.844,-146.494C391.208,-136.555 359.922,-123.934 333.793,-113.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"335.006,-110.109 324.422,-109.614 332.387,-116.601 335.006,-110.109\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140569415242696 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140568403909768-&gt;140569415242696</title>\n",
       "<path d=\"M241.281,-73.4937C217.589,-63.5991 187.53,-51.045 162.36,-40.5327\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.553,-37.2379 152.976,-36.6136 160.855,-43.6971 163.553,-37.2379\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge76\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.337,-92.8747C359.84,-92.6692 367,-92.2109 367,-91.5 367,-91.0557 364.203,-90.71 359.541,-90.4631\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.447,-86.9582 349.337,-90.1253 359.216,-93.9544 359.447,-86.9582\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge77\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.363,-94.4934C369.405,-94.4041 385,-93.4062 385,-91.5 385,-89.9363 374.506,-88.9839 359.671,-88.6428\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.408,-85.1391 349.363,-88.5066 359.316,-92.1385 359.408,-85.1391\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge79\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.192,-95.9462C378.181,-96.3102 403,-94.8281 403,-91.5 403,-88.5749 383.828,-87.0758 359.503,-87.0028\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.175,-83.5043 349.192,-87.0538 359.21,-90.5042 359.175,-83.5043\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge80\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.222,-97.2129C386.589,-98.2793 421,-96.375 421,-91.5 421,-87.082 392.739,-85.1039 359.627,-85.5655\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.145,-82.0749 349.222,-85.7871 359.294,-89.0733 359.145,-82.0749\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge82\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.369,-98.3215C394.725,-100.278 439,-98.0039 439,-91.5 439,-85.4788 401.053,-83.0831 359.433,-84.3129\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.236,-80.8176 349.369,-84.6785 359.49,-87.813 359.236,-80.8176\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge83\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.347,-99.2866C402.482,-102.299 457,-99.7031 457,-91.5 457,-83.8256 409.283,-81.0592 359.624,-83.2009\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.161,-79.7196 349.347,-83.7134 359.509,-86.7109 359.161,-79.7196\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge85\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.004,-100.114C409.789,-104.338 475,-101.467 475,-91.5 475,-82.0783 416.726,-78.9972 359.005,-82.2567\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.764,-78.7649 349.004,-82.8861 359.204,-85.751 358.764,-78.7649\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge86\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.252,-100.885C417.339,-106.363 493,-103.234 493,-91.5 493,-80.3386 424.548,-76.9632 359.27,-81.374\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.966,-77.8868 349.252,-82.1148 359.483,-84.8677 358.966,-77.8868\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge88\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.104,-101.545C424.453,-108.401 511,-105.053 511,-91.5 511,-78.5561 432.054,-74.9202 359.318,-80.5924\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.774,-77.1257 349.104,-81.4546 359.363,-84.1009 358.774,-77.1257\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge89\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.022,-102.141C431.488,-110.438 529,-106.891 529,-91.5 529,-76.7406 439.323,-72.8732 359.237,-79.8977\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.65,-76.4374 349.022,-80.8588 359.306,-83.4067 358.65,-76.4374\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge91\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.206,-102.707C438.631,-112.466 547,-108.73 547,-91.5 547,-74.9089 446.525,-70.8298 359.233,-79.2627\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.796,-75.7892 349.206,-80.2935 359.512,-82.7525 358.796,-75.7892\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge92\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.144,-103.196C445.488,-114.5 565,-110.602 565,-91.5 565,-73.0513 453.518,-68.784 359.098,-78.6982\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.696,-75.2212 349.144,-79.804 359.469,-82.1784 358.696,-75.2212\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge94\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.279,-103.666C452.432,-116.528 583,-112.473 583,-91.5 583,-71.2032 460.712,-66.751 359.332,-78.1434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.798,-74.6821 349.279,-79.3342 359.621,-81.6335 358.798,-74.6821\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge95\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.345,-104.091C459.254,-118.556 601,-114.359 601,-91.5 601,-69.3327 467.706,-64.715 359.409,-77.647\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.831,-74.192 349.345,-78.9095 359.703,-81.1376 358.831,-74.192\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge97\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.407,-104.482C466.014,-120.583 619,-116.256 619,-91.5 619,-67.4452 474.556,-62.6782 359.397,-77.1989\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.863,-73.739 349.407,-78.5177 359.779,-80.6788 358.863,-73.739\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge98\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.095,-104.792C472.391,-122.618 637,-118.188 637,-91.5 637,-65.5422 481.27,-60.6409 359.298,-76.796\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.521,-73.3701 349.095,-78.2084 359.481,-80.3039 358.521,-73.3701\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge100\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.321,-105.152C479.198,-124.639 655,-120.088 655,-91.5 655,-63.638 488.012,-58.6081 359.299,-76.4103\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.719,-72.9576 349.321,-77.8482 359.718,-79.886 358.719,-72.9576\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568403909768 -->\n",
       "<g class=\"edge\" id=\"edge101\"><title>140568403909768-&gt;140568403909768</title>\n",
       "<path d=\"M349.259,-105.447C485.705,-126.664 673,-122.016 673,-91.5 673,-61.7294 494.739,-56.5779 359.34,-76.0456\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"358.631,-72.6126 349.259,-77.5534 359.666,-79.5356 358.631,-72.6126\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140568400437992 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140568400437992</title>\n",
       "<polygon fill=\"none\" points=\"213,-0.5 213,-36.5 355,-36.5 355,-0.5 213,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284\" y=\"-14.8\">decoder_output: Dense</text>\n",
       "</g>\n",
       "<!-- 140568403909768&#45;&gt;140568400437992 -->\n",
       "<g class=\"edge\" id=\"edge102\"><title>140568403909768-&gt;140568400437992</title>\n",
       "<path d=\"M282.484,-73.3129C282.71,-65.2895 282.985,-55.5475 283.237,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"286.737,-46.6235 283.52,-36.5288 279.74,-46.4263 286.737,-46.6235\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19900/19900 [==============================] - 83s 4ms/step - loss: 10.3348 - decoder_output_loss: 1.7521 - decoder_output_acc: 0.7791 - decoder_output_acc_1: 0.9012 - decoder_output_acc_2: 0.6531 - decoder_output_acc_3: 0.3020 - decoder_output_acc_4: 0.8738 - decoder_output_acc_5: 0.6595 - decoder_output_acc_6: 0.3542 - decoder_output_acc_7: 0.8201 - decoder_output_acc_8: 0.5575 - decoder_output_acc_9: 0.3560\n",
      "Epoch 2/10\n",
      "19900/19900 [==============================] - 63s 3ms/step - loss: 2.9739 - decoder_output_loss: 0.7291 - decoder_output_acc: 0.9729 - decoder_output_acc_1: 0.9742 - decoder_output_acc_2: 0.8471 - decoder_output_acc_3: 0.6982 - decoder_output_acc_4: 0.9997 - decoder_output_acc_5: 0.9710 - decoder_output_acc_6: 0.8546 - decoder_output_acc_7: 0.9996 - decoder_output_acc_8: 0.8815 - decoder_output_acc_9: 0.7251\n",
      "Epoch 3/10\n",
      "19900/19900 [==============================] - 64s 3ms/step - loss: 1.3036 - decoder_output_loss: 0.2848 - decoder_output_acc: 0.9808 - decoder_output_acc_1: 0.9810 - decoder_output_acc_2: 0.8671 - decoder_output_acc_3: 0.9404 - decoder_output_acc_4: 0.9999 - decoder_output_acc_5: 0.9785 - decoder_output_acc_6: 0.9276 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9387 - decoder_output_acc_9: 0.8868\n",
      "Epoch 4/10\n",
      "19900/19900 [==============================] - 64s 3ms/step - loss: 0.9469 - decoder_output_loss: 0.2096 - decoder_output_acc: 0.9844 - decoder_output_acc_1: 0.9859 - decoder_output_acc_2: 0.8903 - decoder_output_acc_3: 0.9625 - decoder_output_acc_4: 0.9998 - decoder_output_acc_5: 0.9828 - decoder_output_acc_6: 0.9407 - decoder_output_acc_7: 1.0000 - decoder_output_acc_8: 0.9482 - decoder_output_acc_9: 0.9121\n",
      "Epoch 5/10\n",
      "19900/19900 [==============================] - 69s 3ms/step - loss: 0.6891 - decoder_output_loss: 0.1570 - decoder_output_acc: 0.9887 - decoder_output_acc_1: 0.9893 - decoder_output_acc_2: 0.9404 - decoder_output_acc_3: 0.9808 - decoder_output_acc_4: 0.9999 - decoder_output_acc_5: 0.9849 - decoder_output_acc_6: 0.9500 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9634 - decoder_output_acc_9: 0.9362\n",
      "Epoch 6/10\n",
      "19900/19900 [==============================] - 68s 3ms/step - loss: 0.4371 - decoder_output_loss: 0.1049 - decoder_output_acc: 0.9942 - decoder_output_acc_1: 0.9950 - decoder_output_acc_2: 0.9844 - decoder_output_acc_3: 0.9957 - decoder_output_acc_4: 0.9999 - decoder_output_acc_5: 0.9874 - decoder_output_acc_6: 0.9579 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9789 - decoder_output_acc_9: 0.9620\n",
      "Epoch 7/10\n",
      "19900/19900 [==============================] - 65s 3ms/step - loss: 0.2599 - decoder_output_loss: 0.0625 - decoder_output_acc: 0.9980 - decoder_output_acc_1: 0.9982 - decoder_output_acc_2: 0.9951 - decoder_output_acc_3: 0.9988 - decoder_output_acc_4: 1.0000 - decoder_output_acc_5: 0.9901 - decoder_output_acc_6: 0.9669 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9903 - decoder_output_acc_9: 0.9787\n",
      "Epoch 8/10\n",
      "19900/19900 [==============================] - 65s 3ms/step - loss: 0.1878 - decoder_output_loss: 0.0480 - decoder_output_acc: 0.9993 - decoder_output_acc_1: 0.9995 - decoder_output_acc_2: 0.9977 - decoder_output_acc_3: 0.9995 - decoder_output_acc_4: 1.0000 - decoder_output_acc_5: 0.9915 - decoder_output_acc_6: 0.9769 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9915 - decoder_output_acc_9: 0.9820\n",
      "Epoch 9/10\n",
      "19900/19900 [==============================] - 70s 4ms/step - loss: 0.1662 - decoder_output_loss: 0.0443 - decoder_output_acc: 0.9998 - decoder_output_acc_1: 0.9997 - decoder_output_acc_2: 0.9988 - decoder_output_acc_3: 0.9995 - decoder_output_acc_4: 1.0000 - decoder_output_acc_5: 0.9929 - decoder_output_acc_6: 0.9787 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9911 - decoder_output_acc_9: 0.9850\n",
      "Epoch 10/10\n",
      "19900/19900 [==============================] - 65s 3ms/step - loss: 0.1207 - decoder_output_loss: 0.0313 - decoder_output_acc: 0.9999 - decoder_output_acc_1: 1.0000 - decoder_output_acc_2: 0.9992 - decoder_output_acc_3: 0.9999 - decoder_output_acc_4: 1.0000 - decoder_output_acc_5: 0.9950 - decoder_output_acc_6: 0.9849 - decoder_output_acc_7: 0.9999 - decoder_output_acc_8: 0.9928 - decoder_output_acc_9: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd88803b240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, decoder_state, decoder_cell_state], outputs, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_dates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the test data (human readable dates to one-hot encoded vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for t in data.itertuples():\n",
    "    h, m = t.human, t.machine\n",
    "    X_test.append(h)\n",
    "    Y_test.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the values from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: saturday april 11 2015\n",
      "output: 2015-04-11\n",
      "source: 8 may 1990\n",
      "output: 1990-05-08\n",
      "source: 9 aug 2017\n",
      "output: 2017-08-09\n",
      "source: sunday november 19 1989\n",
      "output: 1989-11-19\n",
      "source: 15 mar 1985\n",
      "output: 1985-03-15\n",
      "source: saturday july 27 1991\n",
      "output: 1991-07-27\n",
      "source: june 2 1972\n",
      "output: 1972-06-02\n",
      "source: thursday july 17 1975\n",
      "output: 1975-07-17\n",
      "source: may 11 2006\n",
      "output: 2006-05-11\n",
      "source: 5 dec 2007\n",
      "output: 2007-12-05\n",
      "source: tuesday september 27 2011\n",
      "output: 2011-09-27\n",
      "source: may 20 1973\n",
      "output: 1973-05-20\n",
      "source: may 1 1997\n",
      "output: 1997-05-01\n",
      "source: sunday september 6 2009\n",
      "output: 2009-09-06\n",
      "source: monday july 16 1990\n",
      "output: 1990-07-16\n",
      "source: 3 june 2015\n",
      "output: 2015-06-03\n",
      "source: december 17 2003\n",
      "output: 2003-12-17\n",
      "source: wednesday january 27 1999\n",
      "output: 1999-01-27\n",
      "source: tuesday december 24 1974\n",
      "output: 1974-12-24\n",
      "source: may 16 1991\n",
      "output: 1991-05-16\n",
      "source: august 7 2015\n",
      "output: 2015-08-07\n",
      "source: thursday september 6 1973\n",
      "output: 1973-09-06\n",
      "source: sunday august 9 1987\n",
      "output: 1987-08-09\n",
      "source: february 24 2004\n",
      "output: 2004-02-24\n",
      "source: saturday december 3 2005\n",
      "output: 2005-12-03\n",
      "source: 8 jun 2014\n",
      "output: 2014-06-08\n",
      "source: friday october 11 1985\n",
      "output: 1985-10-11\n",
      "source: march 3 2001\n",
      "output: 2001-03-03\n",
      "source: 31 may 1995\n",
      "output: 1995-05-31\n",
      "source: 18 november 2012\n",
      "output: 2012-11-18\n",
      "source: october 22 1996\n",
      "output: 1996-10-22\n",
      "source: april 17 1990\n",
      "output: 1990-04-17\n",
      "source: friday december 28 1984\n",
      "output: 1984-12-28\n",
      "source: 11 sep 1986\n",
      "output: 1986-09-11\n",
      "source: may 30 1991\n",
      "output: 1991-05-30\n",
      "source: 29 aug 1996\n",
      "output: 1996-08-29\n",
      "source: sunday april 17 1988\n",
      "output: 1988-04-17\n",
      "source: 10 oct 2009\n",
      "output: 2009-10-10\n",
      "source: 3/13/93\n",
      "output: 1993-03-13\n",
      "source: sunday april 20 1980\n",
      "output: 1980-04-20\n",
      "source: monday november 20 2017\n",
      "output: 2017-11-20\n",
      "source: wednesday april 19 1989\n",
      "output: 1989-04-19\n",
      "source: 05 nov 1978\n",
      "output: 1978-11-05\n",
      "source: 3 april 1999\n",
      "output: 1999-04-03\n",
      "source: 15 mar 1980\n",
      "output: 1980-03-15\n",
      "source: saturday may 7 1977\n",
      "output: 1977-05-07\n",
      "source: 05.05.74\n",
      "output: 1974-05-05\n",
      "source: 11/11/73\n",
      "output: 1973-11-11\n",
      "source: wednesday february 15 1995\n",
      "output: 1995-02-15\n",
      "source: friday september 26 1997\n",
      "output: 1997-09-26\n",
      "source: 22 november 2006\n",
      "output: 2006-11-22\n",
      "source: monday july 3 1989\n",
      "output: 1989-07-03\n",
      "source: 6 june 2006\n",
      "output: 2006-06-06\n",
      "source: friday july 2 2004\n",
      "output: 2004-07-02\n",
      "source: 14 nov 1974\n",
      "output: 1974-11-14\n",
      "source: 8/14/97\n",
      "output: 1997-04-18\n",
      "source: 13 march 2010\n",
      "output: 2010-03-13\n",
      "source: 12 jun 1971\n",
      "output: 1971-06-12\n",
      "source: 16 oct 2008\n",
      "output: 2008-10-16\n",
      "source: monday april 1 1991\n",
      "output: 1991-04-01\n",
      "source: 06 mar 1976\n",
      "output: 1976-03-06\n",
      "source: tuesday july 18 1972\n",
      "output: 1972-07-18\n",
      "source: 08 nov 1970\n",
      "output: 1970-11-08\n",
      "source: 03 feb 2015\n",
      "output: 2015-02-03\n",
      "source: 24 may 2010\n",
      "output: 2010-05-24\n",
      "source: 23 jan 2010\n",
      "output: 2010-01-23\n",
      "source: 11 jan 2008\n",
      "output: 2008-01-11\n",
      "source: 26 may 1976\n",
      "output: 1976-05-26\n",
      "source: friday october 3 1997\n",
      "output: 1997-10-03\n",
      "source: may 7 1980\n",
      "output: 1980-05-07\n",
      "source: wednesday july 11 2012\n",
      "output: 2012-07-11\n",
      "source: monday june 29 1987\n",
      "output: 1987-06-29\n",
      "source: wednesday july 6 1988\n",
      "output: 1988-07-06\n",
      "source: 3/7/86\n",
      "output: 1986-03-07\n",
      "source: feb 26 1995\n",
      "output: 1995-02-26\n",
      "source: saturday april 29 1995\n",
      "output: 1995-04-29\n",
      "source: sunday february 18 2001\n",
      "output: 2001-02-18\n",
      "source: 9 march 2007\n",
      "output: 2007-03-09\n",
      "source: friday november 21 1997\n",
      "output: 1997-11-21\n",
      "source: apr 27 1990\n",
      "output: 1990-04-27\n",
      "source: 11 may 2016\n",
      "output: 2016-05-11\n",
      "source: tuesday october 17 1972\n",
      "output: 1972-10-17\n",
      "source: may 10 1986\n",
      "output: 1986-05-10\n",
      "source: 17 mar 1996\n",
      "output: 1996-03-17\n",
      "source: thursday may 7 1987\n",
      "output: 1987-05-07\n",
      "source: 6/9/81\n",
      "output: 1981-06-06\n",
      "source: 10/1/96\n",
      "output: 1996-10-01\n",
      "source: 21 april 2004\n",
      "output: 2004-04-21\n",
      "source: 7 sep 1998\n",
      "output: 1998-09-07\n",
      "source: 15.06.18\n",
      "output: 2018-06-15\n",
      "source: wednesday july 8 1987\n",
      "output: 1987-07-08\n",
      "source: 9 05 08\n",
      "output: 2008-05-09\n",
      "source: 27 jul 2011\n",
      "output: 2011-07-27\n",
      "source: friday december 13 2013\n",
      "output: 2013-12-13\n",
      "source: sunday september 1 1985\n",
      "output: 1985-09-01\n",
      "source: 18 12 99\n",
      "output: 1999-12-18\n",
      "source: 7 february 1973\n",
      "output: 1973-02-07\n",
      "source: april 30 1974\n",
      "output: 1974-04-30\n",
      "source: 22 may 1971\n",
      "output: 1971-05-22\n",
      "source: may 6 1971\n",
      "output: 1971-05-06\n"
     ]
    }
   ],
   "source": [
    "for example in X_test:\n",
    "    int_vector = data_obj.string_to_int(example, max_input_length, human_vocab)\n",
    "    int_vector = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), int_vector))).swapaxes(0,1)\n",
    "    prediction = model.predict([np.expand_dims(int_vector.T, axis = 0), decoder_state, decoder_cell_state])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
